{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import difflib\n",
    "\n",
    "# 判断材料中的词是否在问题出现过，出现过则为1，没出现过则为0\n",
    "def exist_in_ques(context_word,context_length,question_word,question_length):\n",
    "    feat=np.zeros(context_word.shape)\n",
    "    for i in tqdm(range(context_word.shape[0])):\n",
    "        word_dict={}\n",
    "        for j in range(question_length[i,0]):\n",
    "            if question_word[i,j] not in word_dict:\n",
    "                word_dict[question_word[i,j]]=1\n",
    "        for j in range(context_length[i,0]):\n",
    "            if context_word[i,j] in word_dict:\n",
    "                feat[i,j]=1\n",
    "    return feat\n",
    "\n",
    "# 以Q长度为划窗，获取每个C中word与Q的Jaccard相似度\n",
    "def jaccard_similarity(context_word,context_length,question_word,question_length):\n",
    "    feat=np.zeros(context_word.shape)\n",
    "    for i in tqdm(range(context_word.shape[0])):\n",
    "        length=question_length[i,0]\n",
    "        sub_q=question_word[i,0:length].astype(np.int32)\n",
    "        for j in range(context_length[i,0]):\n",
    "            sub_c=context_word[i,max(0,j-length//2):min(context_length[i,0],j+length//2)].astype(np.int32)\n",
    "            feat[i,j]=len(np.intersect1d(sub_q,sub_c))/len(np.union1d(sub_q,sub_c))\n",
    "    return feat\n",
    "\n",
    "# 计算Q和C之间的编辑距离/划窗大小\n",
    "def levenshtein_dis(context_word,context_length,question_word,question_length):\n",
    "    feat=np.zeros(context_word.shape)\n",
    "    for i in tqdm(range(context_word.shape[0])):\n",
    "        length=question_length[i,0]\n",
    "        sub_q=question_word[i,0:length].astype(np.int32)\n",
    "        for j in range(context_length[i,0]):\n",
    "            sub_c=context_word[i,max(0,j-length//2):min(context_length[i,0],j+length//2)].astype(np.int32)\n",
    "            leven_cost = 0\n",
    "            s = difflib.SequenceMatcher(None, sub_c, sub_q)\n",
    "            for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "                    if tag == 'replace':\n",
    "                        leven_cost += ((i2 - i1)+ (j2 - j1))\n",
    "                    elif tag == 'insert':\n",
    "                        leven_cost += (j2 - j1)\n",
    "                    elif tag == 'delete':\n",
    "                        leven_cost += (i2 - i1)\n",
    "            feat[i,j]=leven_cost/(len(sub_c)+len(sub_q))\n",
    "    return feat\n",
    "\n",
    "# 计算C词向量与Q词向量的最大余弦相似度\n",
    "def max_similarity(context_word,context_length,question_word,question_length,embedding_matrix):\n",
    "    feat=np.zeros(context_word.shape)\n",
    "    for i in tqdm(range(context_word.shape[0])):\n",
    "        a_vec=embedding_matrix[question_word[i,0:question_length[i,0]].astype(np.int32),:]\n",
    "        c_vec=embedding_matrix[context_word[i,0:context_length[i,0]].astype(np.int32),:]\n",
    "        mat1=np.dot(np.mat(c_vec),np.mat(a_vec).transpose())\n",
    "        a_vec_norm=np.linalg.norm(a_vec,axis=1)\n",
    "        c_vec_norm=np.linalg.norm(c_vec,axis=1)\n",
    "        mat2=np.dot(np.mat(c_vec_norm).transpose(),np.mat(a_vec_norm))\n",
    "        cos_dis=np.max(mat1/mat2,axis=1).reshape((1,-1))\n",
    "        feat[i,0:context_length[i,0]]=cos_dis\n",
    "    return feat\n",
    "        \n",
    "# 手工特征提取\n",
    "def feat_extract(data,embedding_matrix):\n",
    "    context_word,question_word,context_char,question_char,context_length,question_length = data\n",
    "#     # 判断材料中的词是否在问题出现过，出现过则为1，没出现过则为0 (n*400)\n",
    "#     feat_exist_in_ques=np.expand_dims(exist_in_ques(context_word,context_length,question_word,question_length),axis=-1)\n",
    "#     # 以Q长度为划窗，获取每个C中word与Q的Jaccard相似度 (n*400)\n",
    "#     feat_jaccard_similarity=np.expand_dims(jaccard_similarity(context_word,context_length,question_word,question_length),axis=-1)\n",
    "#     # 计算Q和C之间的编辑距离/划窗大小 (n*400)\n",
    "#     feat_levenshtein_dis=np.expand_dims(levenshtein_dis(context_word,context_length,question_word,question_length),axis=-1)\n",
    "    \n",
    "    feat_max_similarity=np.expand_dims(max_similarity(context_word,context_length,question_word,question_length,embedding_matrix),axis=-1)\n",
    "    \n",
    "#     handcraft_feat=np.concatenate((feat_exist_in_ques,feat_jaccard_similarity,feat_levenshtein_dis),axis=-1)\n",
    "    handcraft_feat=feat_max_similarity\n",
    "\n",
    "    return handcraft_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77811/77811 [00:27<00:00, 2875.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77811, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "context_word=np.load('dataset2/train_contw_input.npy') \n",
    "question_word=np.load('dataset2/train_quesw_input.npy') \n",
    "context_char=np.load('dataset2/train_contc_input.npy') \n",
    "question_char=np.load('dataset2/train_quesc_input.npy') \n",
    "context_length=(np.load('dataset2/train_cont_len.npy')).astype(np.int32) \n",
    "question_length=(np.load('dataset2/train_ques_len.npy')).astype(np.int32)\n",
    "train_data=[context_word,question_word,context_char,question_char,context_length,question_length]\n",
    "train_hand_feat=feat_extract(train_data,embedding_matrix)\n",
    "old_feat=np.load('dataset2/train_hand_feat.npy')\n",
    "train_hand_feat=np.concatenate((old_feat,train_hand_feat),axis=-1)\n",
    "print(train_hand_feat.shape)\n",
    "np.save('dataset2/train_hand_feat.npy',train_hand_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9788/9788 [00:03<00:00, 3019.84it/s]\n"
     ]
    }
   ],
   "source": [
    "context_word=np.load('dataset2/dev_contw_input.npy') \n",
    "question_word=np.load('dataset2/dev_quesw_input.npy') \n",
    "context_char=np.load('dataset2/dev_contc_input.npy') \n",
    "question_char=np.load('dataset2/dev_quesc_input.npy') \n",
    "context_length=(np.load('dataset2/dev_cont_len.npy')).astype(np.int32) \n",
    "question_length=(np.load('dataset2/dev_ques_len.npy')).astype(np.int32)\n",
    "dev_data=[context_word,question_word,context_char,question_char,context_length,question_length]\n",
    "dev_hand_feat=feat_extract(dev_data,embedding_matrix)\n",
    "old_feat=np.load('dataset2/dev_hand_feat.npy')\n",
    "dev_hand_feat=np.concatenate((old_feat,dev_hand_feat),axis=-1)\n",
    "np.save('dataset2/dev_hand_feat.npy',dev_hand_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10570/10570 [00:03<00:00, 2872.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10570, 400, 3) (10570, 400, 1)\n",
      "(10570, 400, 4)\n"
     ]
    }
   ],
   "source": [
    "context_word=np.load('dataset2/test_contw_input.npy') \n",
    "question_word=np.load('dataset2/test_quesw_input.npy') \n",
    "context_char=np.load('dataset2/test_contc_input.npy') \n",
    "question_char=np.load('dataset2/test_quesc_input.npy') \n",
    "context_length=(np.load('dataset2/test_cont_len.npy')).astype(np.int32) \n",
    "question_length=(np.load('dataset2/test_ques_len.npy')).astype(np.int32)\n",
    "test_data=[context_word,question_word,context_char,question_char,context_length,question_length]\n",
    "test_hand_feat=feat_extract(test_data,embedding_matrix)\n",
    "old_feat=np.load('dataset2/test_hand_feat.npy')\n",
    "test_hand_feat=np.concatenate((old_feat,test_hand_feat),axis=-1)\n",
    "print(test_hand_feat.shape)\n",
    "np.save('dataset2/test_hand_feat.npy',test_hand_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
